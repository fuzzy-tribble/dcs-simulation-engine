### METADATA ###
name: Explore
version: 1.0.0
authors: ["DCS"]
description: |
  A lightweight interaction sandbox that allows users/players to freely explore and interact with characters. There are no goals, no data collection, and no extra mechanics. Useful for demos and open-ended play.

### ACCESS SETTINGS ###
# Defines who may access/play using a MongoDB-style query on players.
# Examples:
#   - Anyone may play: {}
#   - Players must have a player_id: { "where": { "player_id": { "$exists": true } } }
#   - Only with consent: { "consent_given": true }
#   - Only with expertise data: { "expertise": { "$exists": true } }
access_settings:
  user:
    valid:
      players: {}  # open to any players

### DATA COLLECTION SETTINGS ###
# Defines what data is collected durring and after game play.
data_collection_settings:
  save_runs: false

### CHARACTER SELECTION SETTINGS ###
# Defines what characters may be used for the user/player character (PC) and non-player character (NPC) using a MongoDB-style query on collections characters, players or runs.
# NOTE: if the interface allows users to select PC and NPC characters thats fine, their selection will just be validated against these criteria. If no selection is provided and the query returns multiple characters one will be selected at random. If one character is returned it will be used.
character_settings:
  # A wide range of PC and NPC characters are allowed. PC can be any character with human-like-cognition and NPC can be any other character.
  display_pc_choice_as: "{hid} - {short_description}"
  display_npc_choice_as: "{hid} - {short_description}"
  pc:
    valid:
      characters: { "where": { "common_descriptors": { "$regex": "human-?like-cognition", "$options": "i" } } }
      # characters: { 'where': { hid: 'human-normative' } } # allow only normative human PC
  npc:
    valid:
      characters: {} # allow any NPC character

### ADDITIONAL STOPPING CRITERIA ###
stopping_conditions:
  runtime_seconds: [">=600"] # stop after 10 minutes
  turns: [">=50"]    # stop after 50 total turns

### GAME FLOW/GRAPH SETTINGS ###
# Defines the game lifecycle and objectives, and overall flow using a Langgraph graph of nodes and edges. Nodes are i/o functions. We provide builtins for common functionality (like forms, checkpoints, etc.). 
graph_config:
  # Optional metadata
  name: explore-game-graph
  description: A game flow graph that sets up and continues a scene including abilities checkpoints for character actions.
  # Custom state field values that can be (used in nodes and edges)
  # TODO: add context_overrides to override context values per game if needed
  # context_overrides:
  #   retry_limits:
  #     user: 2
  #     simulator: 2
  state_overrides:
    retry_limits: 
      user: 2
      ai: 2
  ### Graph Nodes ###
  # If kind is "builtin.<name>" then it takes config according to that builtin function definition.
  # If kind is "custom" then it takes provider, model, and system_template that invokes a model and returns a dict/object according to "Output format" in the system_template.
  nodes:
    - name: command_filter
      kind: builtin.command_filter # command builtin func takes command to match "eg. help" and a message to display and/or states updates. It checks for a match in event_draft.content
      kwargs:
        command_handlers:
          help:
            special_user_message:
              type: info
              content: |
                Describe an action...
                - Eg. If your character can see and move you might say "I look around the room and walk to the door."

                Here is are reminder of your character's abilities:
                {{ pc.abilities }}
    - name: enter_message
      kind: builtin.update_state # message builtin func takes a message: str and displays writes it to special_user_message so the user can see it without it being part of the message history.
      kwargs:
        state_updates:
          special_user_message:
            type: info
            content: |
              # Welcome
              In this game there is no predefined objective or task. You can just engage freely with the other character. 

              You are playing as: {{ pc.hid }} ({{ pc.short_description }})
              
              The simulator is playing as: {{ npc.hid }} ({{ npc.short_description }})
          lifecycle: UPDATE
    - name: exit_message
      kind: builtin.update_state
      kwargs:
        state_updates:
          special_user_message:
            type: info
            content: |
              Game exited with reason: {{ exit_reason }}
    - name: complete_message
      kind: builtin.update_state
      kwargs:
        state_updates:
          special_user_message:
            type: info
            content: |
              # Game Complete
              The game has completed after {{ len(events) }} total turns.
    - name: error_in_checkpoint
      kind: builtin.raise_error
      kwargs:
        message: |
          An unhandled checkpoint condiftion was reached...
          - invalid_reason: {{ invalid_reason }}
          - event_draft: {{ event_draft }}
          - retries: {{ retries }}
          - retry_limits: {{ retry_limits }}
    - name: error_in_lifecycle
      kind: builtin.raise_error # error builtin funct takes a message: str and raises an error with that message.
      kwargs:
        message: |
          An unhandled lifecycle status was reached: {{ lifecycle }}
    - name: user_max_retry_exit
      kind: builtin.update_state # update_state builtin func takes state_updates: dict[str, Any] and updates the game state with those values.
      kwargs:
        state_updates:
          lifecycle: EXIT
          exit_reason: "maximum retries exceeded"
    - name: simulator_max_retry_exit
      kind: builtin.update_state # update_state builtin func takes state_updates: dict[str, Any] and updates the game state with those values.
      kwargs:
        state_updates:
          lifecycle: EXIT
          exit_reason: "simulator could not produce valid response within retry limit"
    - name: retry
      kind: builtin.retry # retry builtin func takes event_draft, invalid_reason?, increments retries for event_draft.type, gathers a user retry message if type is user, and returns updated message draft with guidance if type is simulator.
      kwargs:
        retry_message: |
          Your previous action was invalid: Please try again.
          Remaining Retries: {{ retry_limits[event_draft.type] - retries[event_draft.type] }}
          Previous Action: {{ event_draft.content }}
          Reason: {{ invalid_reason }}
    - name: checkpoint
      kind: custom
      provider: openrouter
      # model: openai/gpt-5 # works but slow ~20s
      model: openai/gpt-5-mini
      system_template: |
        You are a validator that decides whether the `{{ event_draft.type }}`'s proposed response is valid.

        {% if events|length == 0 %}
        FIRST TURN:
        1. MUST be an opening scene.
        2. MUST begin with: **"You enter a new space. In this space"**
        3. MUST be 2-3 sentences setting a shared scene where both characters could plausibly be present based on their descriptions and abilities.

        {% elif event_draft.type == "user" %}
        USER RESPONSE:
        1. MUST describe plausible observable actions based on their character's abilities. Repeating actions, leaving/returning to the scene or trying multiple times is allowed. For example, 
          - if the user's character can see, "I look around ..." is valid. 
          - if the user's character cannot hear, "I listen for ..." is invalid.
          - "Help me calculate this..." is invalid because it does not describe an observable action.
          - Internal states or conclusions like “I figure out…”, “I realize…” are never valid because they do not describe observable actions.
        2. MUST NOT decide outcomes of their actions. For example,
          - “I look at the man. He looks back at me.” is invalid because it decides the man's reaction.
          - "I reach over tapping the table to try and get his attention." is valid because doesn't decide if the action is successful.
        4. MAY USE ANY OBJECT that could be present (EVEN IF NOT YET MENTIONED!!!). For example,
          - If the scene is a kitchen, and the user's character has hands, they may say "I pick up a knife from the counter" even if knives were not previously mentioned.
          - However, they may NOT use or reference objects that are implausible in the context like a rocket launcher in a chemistry lab.
        5. MAY leave the scene, walk away, etc. as long as they are within the character abilities.

        {% elif event_draft.type == "ai" %}
        SIMULATOR RESPONSE:
        0. Adjudicate the user's last action: 
        Assume success if its within the user character abilities. Report the result of that action in the world. For example, if the user can see and they say "I look around for a light switch", the scene advancement should include something like: "You see a light switch on the wall." If the user's last action was leaving the scene, you may narrate the world and/or simulator character's reaction to that if any.
        1. Sense-bounded narration:
        Only narrate what the user's character could presently perceive through their available senses. For example, if the user's character can see, you may narrate visual details of the scene. If the user's character cannot hear, do not narrate sounds.
        2. Perception-bounded NPC behavior: 
        Simulator characters only react to things they have the ability to detect. If the user does something the user cannot perceive, do not response as if they perceived it; instead narrate what the simulator character is doing/sensing. For example:
          - If the user waves silently and the NPC is blind: do not wave back; instead, output something the blind NPC is doing or sensing at that moment.
          - If the user speaks and the NPC can hear: the NPC may respond verbally or behaviourally to the speech as appropriate.
          - If the user takes an unobservable internal action (“I think about…”): do not respond as if perceived; just continue with the NPC’s plausible next action.
        3. No new user actions / no user internals:
        Do not invent new actions for the user or narrate their thoughts/feelings. Only reflect outcomes of the action they actually took.
        4. Continuity and feasibility
        All narration must remain physically/logically continuous within each characters abilities in context.
        5. Single observable step:
        Advance the scene by one concrete, externally observable outcome (world or simulator character action) at a time. Do not jump ahead multiple steps or narrate future effects.
        6. No unexpressed internals:
        Do not narrate internal states (beliefs/motives/emotions) of any agent unless they are externally expressed through observable behaviour like speech or action. For example, stating an external observable like "exploring a room..." is valid, but "feeling anxious..." or "using mechanosensation..." is invalid unless the character expresses it through action like speaking.
        {% endif %}

        ----
        {% if event_draft.type == 'user' %}
        User/player character Abilities:
        {{ pc.abilities }}
        
        {% elif event_draft.type == 'ai' %}
        Simulator/non-player character Abilities:
        {{ npc.abilities }}
        
        {% endif %}
        ----

        Actions so far: {% if events|length == 0 %} None {% else %}{{ events }}{% endif %}

        Next Proposed action:
        {{ event_draft }}

        Output format: {
            "invalid_reason": str?    # if invalid, provide reason, otherwise omit
            "events": [{            # if valid, copy the Next Proposed Action, otherwise omit
                "type": str?,         
                "content": str?        
              }],
          }
    - name: update
      kind: custom
      provider: openrouter
      # model: deepseek/deepseek-chat-v3-0324 # faster but required retries too much
      model: openai/gpt-5-mini
      system_template: |
        You are the scene-advancer. The user controls their own character. You play only the simulator's character (NPC). You must not speak or act for the user's character.
        - User's character is: {{ pc.short_description }} ({{ pc._short_description }})
        - User character abilities: {{ pc.abilities }}

        - Simulator's character is: {{ npc.short_description }} ({{ npc._short_description }})
        - Simulator character (your character) description: {{ npc.long_description }}
        - Simulator character (your character) abilities: {{ npc.abilities }}
        ----
        When advancing the scene:

        0. Adjudicate the user's last action: 
        Assume success if its within the user character abilities. Report the result of that action in the world. For example, if the user can see and they say "I look around for a light switch", the scene advancement should include something like: "You see a light switch on the wall."

        1. Sense-bounded narration:
        Only narrate what the user's character could presently perceive through their available senses.

        2. Perception-bounded NPC behavior: 
        Simulator characters only react to things they have the ability to detect. If the user does something the user cannot perceive, do not response as if they perceived it; instead narrate what the simulator character is doing/sensing. For example:
          - If the user waves silently and the NPC is blind: do not wave back; instead, output something the blind NPC is doing or sensing at that moment.
          - If the user speaks and the NPC can hear: the NPC may respond verbally or behaviourally to the speech as appropriate.
          - If the user takes an unobservable internal action (“I think about…”): do not respond as if perceived; just continue with the NPC’s plausible next action.
          
        3. No new user actions / no user internals:
        Do not invent new actions for the user or narrate their thoguhts/feelings. Only reflect outcomes of the action they actually took.

        4. Continuity and feasibility
        All narration must remain physically/logically continuous within each characters abilities in context.

        5. Single observable step:
        Advance the scene by one concrete, externally observable outcome (world or simulator character action) at a time. Do not jump ahead multiple steps or narrate future effects.

        6. No unexpressed internals:
        Do not narrate internal states (beliefs/motives/emotions) of any agent unless they are externally expressed through observable behaviour like speech or action.
        {% if not events %}
        Describe a 1-2 sentence opening scene where both characters could plausibly be present, setting the stage for a potential interaction. It should start with "You enter a new space. In this space...".
        For example:
        - If the user's character has the ability to perceive textual/keyboard input, you could set up a computer/typing scene like "You enter a new space. In this space, you sit in front of a keyboard and screen with a chat-like interface open."
        
        Start the opening scene now.
        {% else %}
        Your job is to advance the scene one step in response to the user's last action.

        Provide a response to the last user action now.
        {% endif %}

        Actions so far: 
        
        {% if events|length == 0 %} None {% else %} {{ events }}{% endif %}
        {% if invalid_reason %}
        {{ invalid_reason }}
        
        Provide a response to the last user action and ensure it follows the rules.
        {% endif %}
        Write ONLY the scene output in the following JSON format — no meta-text, no explanations, no reasoning, no restatement of rules.
        Output format: {
          "event_draft": {
            "type": "ai",
            "content": str # a description of how the scene advances including any next actions taken by your NPC - no reasoning, explanations, or extra text.
          }
          "invalid_reason": null,          # don't change this field
        }
  ### Graph Edges ###
  # Defines the flow between nodes including conditionals and branching. Conditionals on state variables is used to direct flow to a single output node (no parallization is supported).
  # __START__ and __END__ are special Langgraph nodes that indicate the start and end of the graph.
  edges:
    - from: __START__
      to: 
        conditional:
          # sometimes system writes a message to user
          - if: "state['special_user_message']"
            then: __END__ # end graph so special message is displayed
          # on first turn, show welcome message
          - if: "state['lifecycle'] == 'ENTER'"
            then: enter_message
          # on exit lifecycle, show exit message
          - if: "state['lifecycle'] == 'EXIT'"
            then: exit_message
          - if: "state['lifecycle'] == 'UPDATE' and state['event_draft']['type'] == 'user'"
            then: command_filter
          - if: "state['lifecycle'] == 'UPDATE' and state['event_draft']['type'] == 'ai'"
            then: update
          - else: error_in_lifecycle
    
    # after welcome message, run update node to setup initial scene
    - from: enter_message
      to: update

    # after exit message, end the graph
    - from: exit_message
      to: __END__

    # after users message has gone through command filter, 
    # end if special usermessage else continue lifecycle handling
    - from: command_filter
      to: 
        conditional:
          - if: "state['special_user_message']"
            then: __END__ # end graph so special message is displayed
          - else: checkpoint # send users draft to checkpoint for validation
            
    # after simulator turn, always send to checkpoint for validation
    - from: update
      to: checkpoint 

    - from: checkpoint # validate event_draft (either give invalid_reason or add it to events and continue)
      to:
        conditional:
            # if invalid and retries left
          - if: "state['invalid_reason'] and state['retries'][state['event_draft']['type']] < state['retry_limits'][state['event_draft']['type']]"
            then: retry
          # if user invalid and no retries left
          - if: "state['event_draft']['type'] == 'user' and state['invalid_reason'] and state['retries'][state['event_draft']['type']] >= state['retry_limits'][state['event_draft']['type']]"
            then: user_max_retry_exit
          # if simulator turn invalid and no retries left
          - if: "state['event_draft']['type'] == 'ai' and state['invalid_reason'] and state['retries'][state['event_draft']['type']] >= state['retry_limits'][state['event_draft']['type']]"
            then: simulator_max_retry_exit
          # if valid and simulator turn
          - if: "state['event_draft']['type'] == 'ai'"
            then: __END__ # simulator created a valid message - end turn
          # if valid and user message
          - if: "state['event_draft']['type'] == 'user'"
            then: update  # user created a valid message - continue to simulator turn
          - else: error_in_checkpoint


    - from: user_max_retry_exit
      to: exit_message

    - from: simulator_max_retry_exit
      to: exit_message

    - from: retry
      to:
        conditional:
          - if: "{{ state['event_draft']['type'] == 'user' }}"
            then: __END__
          - if: "{{ state['event_draft']['type'] == 'ai' }}"
            then: update
          - else: error_in_checkpoint

